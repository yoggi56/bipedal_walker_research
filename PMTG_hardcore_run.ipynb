{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoggi/biped_research/env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from math import *\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import ode\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import torch as th\n",
    "import os\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import TD3, SAC\n",
    "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy, plot_results\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, VecMonitor\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "\n",
    "from bipedalWalkerPMTG import BipedalWalkerPMTG\n",
    "\n",
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put here the address with your learned agent\n",
    "log_dir = \"/home/yoggi/biped_research/models/PMTG_SAC-bipedalWalkerHardcore-model/best_single/2022-10-13_08-09-02_model\"\n",
    "# address where to save a video with the learned agent\n",
    "video_dir = \"/home/yoggi/biped_research/models/PMTG_SAC-bipedalWalkerHardcore-model/best_single/2022-10-13_08-09-02\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create environment and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env = BipedalWalkerPMTG(\n",
    "    is_hard=True, \n",
    "    action_repeat=1, \n",
    "    act_noise=0.0, \n",
    "    rew_scale=1.0, \n",
    "    learn=False,\n",
    "    vel_ctrl=False,)\n",
    "\n",
    "model = SAC.load(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start simulation\n",
    "\n",
    "If you see any warnings about wrapping a monitor, ignore it. It's not a problem in this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 305.9833713046205\n"
     ]
    }
   ],
   "source": [
    "it = 0\n",
    "obs = eval_env.reset()\n",
    "r = 0\n",
    "while it < 35:\n",
    "    action, _states = model.predict(obs, deterministic=False)\n",
    "    obs, rewards, done, info = eval_env.step(action)\n",
    "    eval_env.render()\n",
    "    it += 1/50\n",
    "    r += rewards\n",
    "\n",
    "    if done == True:\n",
    "        eval_env.reset()\n",
    "        break\n",
    "print(f\"Reward: {r}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a video with the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up fake display; otherwise rendering will fail\n",
    "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
    "os.environ['DISPLAY'] = ':1'\n",
    "\n",
    "\n",
    "def record_video(env, model, video_length=500, prefix='', video_folder='videos/'):\n",
    "  \"\"\"\n",
    "  :param env_id: (gym environment)\n",
    "  :param model: (RL model)\n",
    "  :param video_length: (int)\n",
    "  :param prefix: (str)\n",
    "  :param video_folder: (str)\n",
    "  \"\"\"\n",
    "  video_env = DummyVecEnv([lambda: env])\n",
    "  # Start the video at step=0 and record 500 steps\n",
    "  video_env = VecVideoRecorder(video_env, video_folder=video_folder,\n",
    "                              record_video_trigger=lambda step: step == 0, video_length=video_length,\n",
    "                              name_prefix=prefix)\n",
    "\n",
    "  obs = video_env.reset()\n",
    "  for _ in range(video_length):\n",
    "      action, _ = model.predict(obs)\n",
    "      obs, _, done, _ = video_env.step(action)\n",
    "      if done == True:\n",
    "        break\n",
    "\n",
    "  # Close the video recorder\n",
    "  video_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "_XSERVTransSocketUNIXCreateListener: ...SocketCreateListener() failed\n",
      "_XSERVTransMakeAllCOTSServerListeners: server already running\n",
      "(EE) \n",
      "Fatal server error:\n",
      "(EE) Cannot establish any listening sockets - Make sure an X server isn't already running(EE) \n"
     ]
    }
   ],
   "source": [
    "record_video(eval_env, model, video_length=1500, video_folder=video_dir, prefix=\"bipedWalker_PMTG_SAC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full agent evaluation (mean reward over 100 episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yoggi/biped_research/env/lib/python3.8/site-packages/stable_baselines3/common/evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward: 303.3886143073267 +/- 10.82\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=100, deterministic=True, render=False, callback=None,\n",
    "                              reward_threshold=None)\n",
    "print(f'Mean reward: {mean_reward} +/- {std_reward:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38513d5fc8944757278d1305d220fcdba7cc001081561143afc16cb99cb5ffdf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
